---
title: "SAT - HW 10 Template"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
library("tidyverse")
library("rstan") # observe startup messages
library("shinystan")
library("bayesplot")
library("matrixStats")
library("gridExtra")
library("mosaic")
options(mc.cores = parallel::detectCores()) #want to run the chains in parallel
rstan_options(auto_write = TRUE) #write a complied version to the disk 
```

```{r}
# Read in and edit the data

sat_data <- read_csv('Guber1999data.csv')
# Normalize in R, transform back in Stan
sat_data <- mutate(sat_data, z_spend = as.numeric(scale(sat_data$Spend)), 
                   z_ptake = as.numeric(scale(sat_data$PrcntTake)), 
                   z_sat = as.numeric(scale(sat_data$SATT)))

# Create and normalize interaction variable
sat_data <- mutate(sat_data, spend_pct = Spend*PrcntTake) 
sat_data <- mutate(sat_data, z_spend_pct = as.numeric(scale(Spend*PrcntTake))) 
```



### General Instructions
- DO echo your R code in your output.
- Upload in your .Rmd, .stan, and .html files to Schoology.  Do not zip.
- Load libraries and data in this section.  
- Put the code and text in their respective sections.


### EDA
Include three scatterplots of SATT by Spend, SATT by PercntTake, and Spend by PercntTake, and comment on what you see. Calculate the correlation of Spend and PercntTake and comment on its value.

These plots show negative relationships between spending and SATT scores, and between the percentage of students who take the SAT and the average SAT score. The scatterplot of average SATT score versus percent of students who took the SAT shows a very clear negative linear relationship between percent and average score. The plot of percent taking the SAT versus spending shows a positive relationship between these two variables, which is confirmed by the correlation coefficient of 0.593. 

```{r}
ggplot(data=sat_data)+
  geom_point(mapping = aes(x=Spend,y=SATT)) + xlab("Spending")
# ggplot(data=sat_data)+
#   geom_point(mapping = aes(x=StuTeaRat,y=SATT))

ggplot(data=sat_data)+
  geom_point(mapping = aes(x=PrcntTake,y=SATT))+xlab("Percent of Students who took SAT")

# ggplot(data=sat_data)+
#   geom_point(mapping = aes(x=Salary,y=SATT))

ggplot(data=sat_data)+
  geom_point(mapping = aes(x=Spend,y=PrcntTake))+ylab("Percent of Students who took SAT")+xlab("Spending")

corr_PctTake_Spend=cor(sat_data$Spend,sat_data$PrcntTake)
corr_SATT_Spend = cor(sat_data$Spend,sat_data$SATT)
corr_SATT_PctTake = cor(sat_data$PrcntTake,sat_data$SATT)
```


### Model Description

I'd like you to implement two models.  Use a generalized $t$ distribution for both the likelihood and the priors on all of the slope parameters (code the interaction).  One model does NOT use shrinkage for the slope parameters (Model 1), and one does (Model 2).  Describe your two models in this section, noting the prior distributions you will use.  If you know how to use Latex, please use it to write your distributions and parameters.  Do not put the SAT bounds in your model, it will be hard to do prior predictive checks.



##Model 1

This model doesn't use shrinkage. The model prior has a linear combination of 
 $z_{y_{i}\sim student-t(z_\nu, z_{\beta_{0}{+z_{\beta_{1}}*Spend_{i}+z_{\beta_{2}}*PrcntTake_{i}+z_{\beta_{3}}*Spend_{i}*PrcntTake_{i}, z_\sigma)$, where $i = 1,2,3,...,50$ indicating each state; $z_\nu \sim e^{(1/30)}$, $z_\sigma \sim \frac{1}{2}Normal(0,1)$.

```{r}

# Input for Stan
sat.data <- list(J=3, N=nrow(sat_data),
                 mint = mean(sat_data$spend_pct),
                 mspend = mean(sat_data$Spend), mptake = mean(sat_data$PrcntTake), msat = mean(sat_data$SATT),
                 sspend = sd(sat_data$Spend),sptake = sd(sat_data$PrcntTake),ssat = sd(sat_data$SATT), sint = sd(sat_data$spend_pct),
                 z_spend = sat_data$z_spend,
                 z_ptake = sat_data$z_ptake,
                 z_int = sat_data$z_spend_pct,
                 z_sat = sat_data$z_sat)
fit.m1 <- stan(file = "model1_noshrink.stan",data = sat.data,seed = 42)
save(fit.m1,file = "Model1.Rdata")
load("Model1.Rdata")
launch_shinystan(as.shinystan(fit.m1))

```

### Prior Predictive Checks

Do a prior preditive check for Model 1 that seems reasonable and explain WHY you chose it and what your visual describes.  Just do a single plot, but make sure it's clear to me that you fully understand what it is saying.

We choose a bar chart to display the generated fake data with its mean highlighted which is about 980. The range of scores is reasonable with a wide range of value as the mean of SAT scores.

```{r}
# Prior Predictive Checking
sat.pri.data <- list(J=3, N=nrow(sat_data),
                     spend = sat_data$Spend, 
                     ptake = sat_data$PrcntTake,
                     inter = sat_data$spend_pct,
                 mint = mean(sat_data$spend_pct),
                 mspend = mean(sat_data$Spend),
                 mptake = mean(sat_data$PrcntTake), 
                 msat = mean(sat_data$SATT),
                 sspend = sd(sat_data$Spend),
                 sptake = sd(sat_data$PrcntTake),
                 ssat = sd(sat_data$SATT), 
                 sint = sd(sat_data$spend_pct))

fit.prior.m1 <- stan(file = 'model1_pri_noshrink.stan', data = sat.pri.data, seed = 21,control = list(adapt_delta = 0.999))
launch_shinystan(as.shinystan(fit.prior.m1))

save(fake.data.stan,file = "Prior_fit.Rdata")
load("prior_fit.rdata")

set.seed(21)
fake.data.stan <- as.matrix(as.data.frame(fit.prior.m1) %>% select(contains("y_fake")) %>% sample_n(size = 100))


#prior predictive check for the fake data vs. real data
ppc_stat(sat_data$SATT, fake.data.stan)
# ppc_stat(sat_data$SATT, fake.data.stan, stat = "sd")
# ppc_stat(sat_data$SATT, fake.data.stan, stat = "min")
# ppc_dens_overlay(sat_data$SATT, fake.data.stan) 
# samples <- as.data.frame(fit.prior.m1)%>%
#   sample_n(size = 30)%>%
#   select(contains("y_fake"))
#ppc_dens_overlay(y=as.numeric(sat_data$SATT), yrep = as.matrix(samples))
```


## Model 2

This model is with shrinkage. The model prior has a linear combination of 
$z_{y_{i}\sim student-t(z_\nu, z_{\beta_{0}{+z_{\beta_{1}}*z_{Spend_{i}}+z_{\beta_{2}}*z_{PrcntTake_{i}}+z_{\beta_{3}}*z_{Spend_{i}*PrcntTake_{i}}, z_\sigma)$, where $i = 1,2,3,...,50$ indicating each subject; $z_\nu \sim e^{(1/30)}$, $z_\sigma \sim Normal(0,1)$, $z_{\beta_{0,1,2,3}}\sim student-t(1, \mu, \sigma)$ 
where $\mu\sim Normal(0,1)$, $\sigma\sim Gamma(2,2)$. We choose 1 for $nu$ for $z_\beta$'s because we want them to add thickness to the tails to account for outliers. We gave the standarad deviation of hyper params a distribution of $\sigma\sim\gamma(2,2)$. 

```{r}
# Input for Stan, Shrinkage Model
sat.data <- list(J=3, hypers = c(2,2),
                 N=nrow(sat_data),
                 spend = sat_data$Spend, 
                 ptake = sat_data$PrcntTake,
                 inter = sat_data$spend_pct,
                 mint = mean(sat_data$spend_pct),
                 mspend = mean(sat_data$Spend), 
                 mptake = mean(sat_data$PrcntTake), 
                 msat = mean(sat_data$SATT),
                 sspend = sd(sat_data$Spend),
                 sptake = sd(sat_data$PrcntTake),
                 ssat = sd(sat_data$SATT), 
                 sint = sd(sat_data$spend_pct),
                 z_spend = sat_data$z_spend,
                 z_ptake = sat_data$z_ptake,
                 z_int = sat_data$z_spend_pct,
                 z_sat = sat_data$z_sat)
fit.m2 <- stan(file = "model2_shrink.stan",data = sat.data, seed = 42, control = list(adapt_delta = 0.95))

save(fit.m2,file = "Model2.Rdata")
load("Model2.Rdata")
launch_shinystan(as.shinystan(fit.m2))

```

### Hierarchical Modeling
Fit both models using the standardized data and then transform back to parameters on the original scale. 
We used ghe same hyper for sigma of the betas because we assume that the $\beta_{1,2,3}$ are from the same distribution except $\beta_0$. We gave the sigma hyper parameter a $\sigma\sim\gamma(2,2)$. 

### Model Diagnostics
Just write a sentence or two describing what you noticed in Shinystan when you ran the models. Remember to increase the number of digits in Stan's output.

The $\hat{R}$'s have values of 1 and the trace plots look well-mixed. This shows the chains have converged to the same values.

### Posterior Predictive Checks

```{r}
# Posterior Predictive Checks
set.seed(2)

fake.data2.post.stan <- as.matrix(as.data.frame(fit.m2) %>% select(contains("y_fake")) %>% sample_n(size = 100))


# Posterior predictive check for the fake data vs. real data 

# Model 2
grid.arrange(grobs = list(
ppc_stat(sat_data$SATT, fake.data2.post.stan)+xlab("Mean")+ggtitle("Model 2 Posterior Predictive Check"),
# ppc_stat(sat_data$SATT,stat = "max",fake.data.post.stan)+xlab("Max")+legend_none(),
ppc_stat(sat_data$SATT,stat = "sd",fake.data2.post.stan)+xlab("Standard Deviation")
# ,ppc_stat(sat_data$SATT,stat = "max",fake.data.post.stan)+legend_none()+xlab("Max")
))
```




### Conclusions
Answer the following questions, using credible intervals as your evidence.  

1. (Model 1) Is there evidence that the slope parameters are not zero?  

The posterior distribution results for our parameters $\beta_0$,$\beta_1$,$\beta_2$, and $\beta_3$ show that the 

2. (Model 1) What inference can you make about the effect of Spend and PercntTake on SATT? Interpret this in the context of the interaction.

3. How is Model 2 different from Model 1?  Can you explain why?  Do you have any questions about your results?





